[package]
name = "mini-langchain"
version = "0.1.0"
edition = "2024"
authors = ["Rollp0x zkrollp@gmail.com"]
description = "Minimal Rust LangChain implementation for text-only interactions"
license = "MIT OR Apache-2.0"
repository = "https://github.com/Rollp0x/mini-langchain"
keywords = ["langchain", "llm", "ai", "agent", "tool-calling"]
categories = ["development-tools", "api-bindings"]

[features]
# Enable to use upstream ollama-rs streaming APIs (gates code in ollama.rs)
# This maps our feature `ollama_stream` to the upstream crate feature `stream`.
ollama_stream = ["ollama-rs/stream"]

[dependencies]
## Async runtime
tokio = { version = "1", features = ["full"] }
async-trait = "0.1"
futures = "0.3"

## HTTP client
reqwest = { version = "0.12", features = ["json", "stream"] }

## Serialization
serde = { version = "1", features = ["derive"] }
serde_json = "1"
toml = "0.8"

## Error handling
thiserror = "1"
anyhow = "1"

## Logging
tracing = "0.1"
tracing-subscriber = "0.3"
ollama-rs = "0.3.2"

# proc-macro for generating Tool wrappers
mini-langchain-macros = "0.1.0"
async-stream = "0.3.6"
async-openai = "0.30.1"

[dev-dependencies]
tokio-test = "0.4"
mockito = "1"
